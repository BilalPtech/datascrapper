{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        return soup\n",
    "    else:\n",
    "        raise Exception(f\"Failed to retrieve content. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_hrefs(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    all_hrefs = set()\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        \n",
    "        content_area = soup.find('div', class_='content-area')\n",
    "        if not content_area:\n",
    "            break\n",
    "        \n",
    "        articles = content_area.find_all('article')\n",
    "        for article in articles:\n",
    "            article_header = article.find('header',{'class':'entry-header'})\n",
    "            article_h2 = article_header.find('h2',{'class':'entry-title'})\n",
    "            a = article_h2.find('a')\n",
    "            href = a.get('href')\n",
    "            if href:\n",
    "                all_hrefs.add(href)\n",
    "\n",
    "        try:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/1.2);\")\n",
    "            time.sleep(2)\n",
    "            older_posts_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//div[@class=\"content-area\"]//main[@class=\"site-main\"]//div[@id=\"infinite-handle\"]//button[text()=\"Older posts\"]'))\n",
    "            )\n",
    "            print(older_posts_button)\n",
    "            older_posts_button.click()\n",
    "            print('OlderPost Btn Clicked')\n",
    "            time.sleep(5)\n",
    "\n",
    "        except TimeoutException:\n",
    "            print('TimeoutException')\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return list(all_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_div(parent_div):\n",
    "    writing = []\n",
    "    links = []\n",
    "    extracted_data = {}\n",
    "\n",
    "    for child in parent_div.children:\n",
    "        tag_name = child.name\n",
    "\n",
    "        if tag_name == 'p':\n",
    "            text = child.get_text(strip=True)\n",
    "            if text:\n",
    "                writing.append(text)\n",
    "            else:\n",
    "                images = child.find_all('img')\n",
    "                for img in images:\n",
    "                    img_src = img.get('src')\n",
    "                    if img_src:\n",
    "                        links.append(img_src)\n",
    "        elif tag_name == 'div' and child.get('id') != \"jp-post-flair\":\n",
    "            print('we in div')\n",
    "            images = child.find_all('img')\n",
    "            for img in images:\n",
    "                img_src = img.get('src')\n",
    "                if img_src:\n",
    "                    links.append(img_src)\n",
    "        elif tag_name == 'figure':\n",
    "            print('we in figure')\n",
    "            images = child.find_all('img')\n",
    "            for img in images:\n",
    "                img_src = img.get('src')\n",
    "                if img_src:\n",
    "                    links.append(img_src)\n",
    "\n",
    "            iframes = child.find_all('iframe')\n",
    "            for iframe in iframes:\n",
    "                iframe_src = iframe.get('src')\n",
    "                if iframe_src:\n",
    "                    links.append(iframe_src)\n",
    "\n",
    "        elif tag_name in ['ol', 'ul']:\n",
    "            list_items = child.find_all('li')\n",
    "            for item in list_items:\n",
    "                item_text = item.get_text(strip=True)\n",
    "                if item_text:\n",
    "                    writing.append(item_text)\n",
    "\n",
    "    extracted_data['Text'] = writing\n",
    "    extracted_data['mediaLinks'] = links\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =['2018','2019','2020','2021','2022','2023','2024']\n",
    "main_url = \"https://eastcroydoncool.co.uk/\"\n",
    "soup = get_soup(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "brand_div = soup.find('div',{'class':'site-branding-text'})\n",
    "brand_p = brand_div.find('p',{'class':'site-title'})\n",
    "data[\"site_url\"] = brand_p.find('a')['href']\n",
    "data[\"site_title\"] = brand_p.find('a').text\n",
    "data['site_description'] = brand_div.find('p',{'class':'site-description'}).text\n",
    "data[\"AllContent\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"8a1566caf937d5391cb5729b5d460c7f\", element=\"f.50F9FC746066EE26CEC9E63A96287ADB.d.B21FEBCD02A2BC9A0D70F44EA4598C12.e.39\")>\n",
      "OlderPost Btn Clicked\n",
      "TimeoutException\n"
     ]
    }
   ],
   "source": [
    "url = \"https://eastcroydoncool.co.uk/2018\"\n",
    "yearly_links = get_article_hrefs(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['https://eastcroydoncool.co.uk/2018/04/05/east-croydon-cool-talks-theatre/', 'https://eastcroydoncool.co.uk/2018/07/04/east-croydon-cool-talkship-hop/', 'https://eastcroydoncool.co.uk/2018/10/23/east-croydon-cool-talks-croydon-literary-festival/', 'https://eastcroydoncool.co.uk/2018/10/10/east-croydon-cool-talks-counselling/', 'https://eastcroydoncool.co.uk/2018/06/10/east-croydon-cool-talks-photography/', 'https://eastcroydoncool.co.uk/2018/08/24/east-croydon-cool-talks-risefestival/', 'https://eastcroydoncool.co.uk/2018/04/16/east-croydon-cool-talks-yoga/', 'https://eastcroydoncool.co.uk/2018/05/29/east-croydon-cool-talks-personal-training/', 'https://eastcroydoncool.co.uk/2018/06/10/croydoniscool-tweet-chat/', 'https://eastcroydoncool.co.uk/2018/05/11/east-croydon-cool-talks-graffiti/', 'https://eastcroydoncool.co.uk/2018/06/25/east-croydon-cool-talks-homelessness/', 'https://eastcroydoncool.co.uk/2018/08/06/east-croydon-cool-talks-jewellery-design/', 'https://eastcroydoncool.co.uk/2018/07/16/east-croydon-cool-talks-performance-art-and-noise/', 'https://eastcroydoncool.co.uk/2018/10/06/east-croydon-cool-talks-illustration/', 'https://eastcroydoncool.co.uk/2018/09/11/east-croydon-cool-talks-virtual-reality/']\n"
     ]
    }
   ],
   "source": [
    "print(len(yearly_links))\n",
    "print(yearly_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eastcroydoncool.co.uk/2018/10/06/east-croydon-cool-talks-illustration/\n"
     ]
    }
   ],
   "source": [
    "article = yearly_links[13]\n",
    "print(article)\n",
    "blog = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_soup = get_soup('https://eastcroydoncool.co.uk/2019/12/18/east-croydon-cool-talks-interior-design/')\n",
    "article_sec = article_soup.find('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = article_sec.find('header',{'class':'entry-header'})\n",
    "blog['Title'] = header.find('h1').text.strip()\n",
    "blog['postTimeDate'] = header.find('time').text.strip()\n",
    "art_div = article_sec.find('div',{'class':'entry-content'})\n",
    "data = extract_content_from_div(art_div)\n",
    "with open('data/test.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome\n",
      "Croydon and Cool? Say wuuut?! It’s fair to say Croydon isn’t generally considered the epitome of cool. But like all underdogs – there’s way more to it than it’s given credit for.  This big (Brutalist) slab of concrete (surrounded by acres of countryside) has seen a lot of changes in recent years. In East Croydon, there are more entertainment options thanks to the arrival of Boxpark and the refurbishment of Fairfield Halls. There are increased education opportunities courtesy of a new London South Bank University campus and a partnership between Croydon College and the University of Roehampton. There are more enterprise possibilities due to a start-up culture fostered by the likes of Sussex Innovation Centre and Start Up Croydon. The restaurant and bar scene (celebrated at the annual Croydon Food Festival) is attracting foodies from across London and the long-awaited “Westfield” project is now underway again. All this in addition to what already made Croydon a great place to be: a thriving creative arts scene (showcased by it’s London Borough of Culture 2023 programme), a vibrant community (based across a network of unique neighbourhoods – from Coulsdon, Purley and Sanderstead in the south to Norbury, Crystal Palace and Upper Norwood in the north) and excellent transport connections (including trains that get you to Central London in 14 mins, Gatwick Airport in 15 mins and Brighton in 45 mins). As a Borough, Croydon has always bred talent – nurturing top international stars on football fields at CPFC and in studios at The Brit School. Well known for being the birthplace of Dubstep, Croydon’s wider music credentials are unrivalled. The Borough boasts a roll-call of iconic artists spanning all genres – from Samuel Coleridge Taylor, Captain Sensible and Desmond Dekker to Skream & Benga, Stormzy and Raye. A new wave of Creatives (supported and celebrated through the Borough’s Creative Enterprise Zone) have made Croydon home – drawn to studios and workspaces like Matthews Yard, Turf, Conditions, Stanley Arts, ASC and Pirate. Croydon now has a record number of new developments and a growing population of workers, students and residents – who are attracted to all the other great things about the area. After a global pandemic, supporting local and investing in community has never been more important. CLICK HERE to learn how East Croydon Cool helps to celebrate and champion people and places across the Borough.\n"
     ]
    }
   ],
   "source": [
    "blog['title'] = soup.find('h1').text.strip()\n",
    "content_div = soup.find('div',{'class':'entry-content'})\n",
    "text_ps = content_div.find_all('p')\n",
    "txt = []\n",
    "for text_p in text_ps:\n",
    "    txt.append(text_p.text)\n",
    "blog['content'] = ' '.join(txt)\n",
    "print(blog['title'])\n",
    "print(blog['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['blogs'].append(blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/complete.json','w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
